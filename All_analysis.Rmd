---
title: "Main and Supplementary Analysis, variability of Insight Seeking"
date: "2024-04-03"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
header-includes:
  - \usepackage{placeins}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results = 'asis')
# Set options for kableExtra
options(knitr.table.format = "latex")
```

```{r library}
library(tidyverse)
library(kableExtra)
library(jtools)
library(lavaan)
library(semTools)
library(lmerTest)
```


This R Markdown document contains the Main and Supplementary Analyses of the paper "Insight-seeking is consistent across domains and distinct from other forms of curiosity". It contains all the code necessary to reproduce the analyses and figures in the paper. The data used in this analysis is available in the `data` folder. The code is organized by study, and each study contains the following sections: data processing, confirmatory analysis, and exploratory analysis.

# Study 1

```{r}
# Prepare dataset and demographics

data_1 = read_csv("Data/Study1_data.csv")

# Suppress people who did not understand explanation of insight
data_1 = data_1 %>% filter(Q6 == 2)

# Select columns with ratings of enjoyment and transform in numeric
media_columns = c("Novel_enjoy", "Movie_enjoy", "Science_enjoy", "Puzzle_enjoy", "Game_enjoy", "Docu_enjoy")
media_ratings = data_1[media_columns]
media_ratings[] <- lapply(media_ratings, function(x) as.numeric(as.character(x)))

media_columns_frequency = c("Novel_regularity", "Movie_regularity", "Science_regularity", "Puzzle_regularity", "Game_regularity", "Docu_regularity")
media_frequency = data_1[media_columns_frequency]
media_frequency[] <- lapply(media_frequency, function(x) as.numeric(as.character(x)))

# Demographics
demo_1 = read_csv("Data/Study1_demo.csv")
demo_1$PROLIFIC_PID = demo_1[["Participant id"]]

# Merge datasets
data_1 = left_join(data_1, demo_1, by = "PROLIFIC_PID")

# Summary stats of participants
table(data_1$Sex)
mean(as.numeric(data_1$Age), na.rm = TRUE)
sd(data_1$Age, na.rm = TRUE)

```

## Descriptive Statistics (ESM)

```{r}
media_ratings %>%
  gather(key = "media", value = "rating") %>%
  group_by(media) %>%
  summarise(mean = mean(rating, na.rm = TRUE), sd = sd(rating, na.rm = TRUE), n_NA = sum(is.na(rating))) %>%
  kable()
```

```{r}
media_frequency %>%
  gather(key = "media", value = "frequency") %>%
  group_by(media) %>%
  summarise(mean = mean(frequency, na.rm = TRUE), sd = sd(frequency, na.rm = TRUE), n_NA = sum(is.na(frequency))) %>%
  kable()
```


## Confirmatory Analyses

**H1**: The mean of all pairwise correlations will be significantly different from chance

```{r}
### Compute actual correlations ###

cor_matrix <- cor(media_ratings, use="pairwise.complete.obs")

# Extract lower triangle without the diagonal
cor_values <- cor_matrix[lower.tri(cor_matrix)]

# Calculate mean of these correlation coefficients
mean_cor <- mean(cor_values)
sd_mean_cor = sd(cor_values)

# Loop through the matrix to extract lower triangle correlations
correlation_table <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
var_names <- colnames(media_ratings)

for (i in 1:(length(var_names)-1)) {
  for (j in (i+1):length(var_names)) {
    pair <- sort(c(var_names[i], var_names[j]))
    pair_name <- paste(pair[1], pair[2], sep="-")
    
    cor_value <- cor_matrix[i, j]
    
    correlation_table <- rbind(correlation_table, data.frame(Pair = pair_name, Correlation = cor_value))
  }
}

rm(cor_value, cor_values, i, j, pair, pair_name, var_names)

### Bootstrapping ###

set.seed(123)  # Ensuring reproducibility

n_iterations <- 1000 

# Initialize an empty data frame to store the results from all iterations
all_bootstrap_results <- data.frame(Iteration = integer(), Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)

for (i in 1:n_iterations) {
  # Randomize dataset: shuffle the ratings within each column
  randomized_data <- as.data.frame(lapply(media_ratings, sample))
  
  # Temporary storage for this iteration's results
  iteration_results <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
  
  var_names <- colnames(randomized_data)
  
  # Compute pairwise correlations
  for (m in 1:(length(var_names)-1)) {
    for (n in (m+1):length(var_names)) {
      # Ensure pair names are always in alphabetical order
      pair <- sort(c(var_names[m], var_names[n]))
      pair_name <- paste(pair[1], pair[2], sep="-")
      
      cor_value <- cor(randomized_data[[m]], randomized_data[[n]], use="pairwise.complete.obs")
      
      # Temporarily store the pair, its correlation, and iteration number
      iteration_results <- rbind(iteration_results, data.frame(Pair = pair_name, Correlation = cor_value))
    }
  }
  
  # Add iteration number to the iteration_results
  iteration_results$Iteration <- i
  
  # Combine this iteration's results with the main storage
  all_bootstrap_results <- rbind(all_bootstrap_results, iteration_results)
}

rm(n, n_iterations, pair, pair_name, var_names, m, i, cor_value, randomized_data)

### Compare bootstrapped results with actual data ###

# Aggregate bootstrap results to find mean correlation per iteration
bootstrap_means <- all_bootstrap_results %>%
  group_by(Iteration) %>%
  summarise(MeanCorrelation = mean(Correlation, na.rm = TRUE))

# Calculate the 95% confidence interval for the bootstrap means
bootstrap_ci <- quantile(bootstrap_means$MeanCorrelation, probs = c(0.025, 0.975), na.rm = TRUE)

# Assuming mean_cor is the mean of actual correlations from correlation_table
is_significantly_higher <- mean_cor > bootstrap_ci[2]  # Check if higher than upper CI bound

# calculate p_value
p_value = mean(bootstrap_means$MeanCorrelation > mean_cor)

# Print the result
print(paste("Is the actual mean correlation significantly higher? ", is_significantly_higher, " with p_val of", p_value))

```

```{r figure 1}
ggplot(bootstrap_means, aes(x = MeanCorrelation)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(xintercept = bootstrap_ci[1], linetype = "dashed", color = "grey", size = 1) +  # Lower CI bound
  geom_vline(xintercept = bootstrap_ci[2], linetype = "dashed", color = "grey", size = 1) +  # Upper CI bound
  geom_vline(xintercept = mean_cor, color = ifelse(is_significantly_higher, "green", "red"), size = 1.5) +  # Actual mean correlation
  theme_minimal() +
  labs(title = "Distribution of Bootstrap Mean Correlations",
       x = "Mean Correlation",
       y = "Count") +
  annotate("text", x = mean_cor, y = Inf, label = sprintf("Actual mean: %.3f", mean_cor), vjust = 2, hjust=1)
```

## ESM

```{r figure S3}
# plot the correlation matrix with a heatmap with the value of correlations
cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column(var = "media") %>%
  gather(key = "media2", value = "correlation", -media) %>%
  ggplot(aes(x = media, y = media2, fill = correlation)) +
  geom_tile() +
  geom_text(aes(label = round(correlation, 2))) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Correlation matrix of media ratings", x = "Media 1", y = "Media 2", fill = "Correlation") +
  theme(legend.position = "right") 
```

**RQ1**: What pairwise correlations across media are significantly different from chance?

```{r figure S4}
# Calculate 95% Confidence Intervals for each Pair
bootstrap_cis <- all_bootstrap_results %>%
  group_by(Pair) %>%
  summarise(Lower = quantile(Correlation, 0.025, na.rm = TRUE),
            Upper = quantile(Correlation, 0.975, na.rm = TRUE))

# Merge the actual correlations with their corresponding CIs
comparison_table <- merge(correlation_table, bootstrap_cis, by = "Pair")

# Determine if actual correlations are significantly higher
comparison_table$Significantly_Higher <- with(comparison_table, Correlation > Upper)


# Merge the actual correlations with their CIs for plotting
vlines_with_cis <- merge(vlines_data, bootstrap_cis, by = "Pair", all.x = TRUE)

# Ensure this flag is included in vlines_with_cis for coloring
vlines_with_cis <- merge(vlines_with_cis, comparison_table[, c("Pair", "Significantly_Higher")], by = "Pair")

# Add a 'Color' column based on significance for plotting
vlines_with_cis$Color <- ifelse(vlines_with_cis$Significantly_Higher, "green", "red")

# Plotting with confidence intervals
ggplot(all_bootstrap_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(data = vlines_with_cis, aes(xintercept = Correlation, color = Color), size = 1) +  # Color based on significance
  geom_vline(data = vlines_with_cis, aes(xintercept = Lower), linetype = "dotted", size = 0.5, color = "gray") +  # CI lower bound in gray
  geom_vline(data = vlines_with_cis, aes(xintercept = Upper), linetype = "dotted", size = 0.5, color = "gray") +  # CI upper bound in gray
  facet_wrap(~ Pair, scales = "free_x") +
  scale_color_identity() +  # Use actual color names provided in the data
  theme_minimal() +
  labs(title = "Distribution of Bootstrapped Correlations by Pair",
       x = "Correlation",
       y = "Count") +
  theme(legend.position = "none")  # No legend needed as colors are self-explanatory

```

```{r}
# if needed, you can clean all memory at this point:  
# rm(list = ls())
```


# Study 2

```{r, data preparation}
data_2 = read_csv("Data/Study2_data.csv")

# filter out participants who did not understand insight
data_2 = data_2 %>%
  filter(Q6 == 2)

# add demographics
demo_2 = read_csv("Data/Study2_demo.csv")
demo_2$PROLIFIC_PID = demo_2[["Participant id"]]

data_2 <- left_join(data_2, 
                    demo_2 %>% select(PROLIFIC_PID, Age, Sex), 
                    by = "PROLIFIC_PID")

table(data_2$Sex)

data_2 %>% 
  summarise(
    mean_Age = mean(as.numeric(Age), na.rm = TRUE),
    sd_Age = sd(Age, na.rm = TRUE),
    mean_time = mean(as.numeric(`Duration (in seconds)`), na.rm = TRUE), 
    sd_time = sd(as.numeric(`Duration (in seconds)`), na.rm = TRUE))
```

```{r}
data_2_cfa = data_2 %>%
  select(starts_with("Novel"), starts_with("Movie"), starts_with("Nonfict"), starts_with("Game"), starts_with("Docu")) %>%
  lapply(as.numeric) %>%
  as.data.frame()

data_2_cfa$ResponseId = data_2$ResponseId
```


## Model Fitting

```{r, Model_1}
model_1 <- "
  # Higher-order factor
  Curiosty =~ Insight_seeking + Explo_curiosity + Morbid_curiosity
  
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  Morbid_curiosity =~ Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

fit_1 = cfa(model_1, data = data_2_cfa, missing = "fiml", optim.method = "BFGS")

summary(fit_1, fit.measures = TRUE)
```


```{r, Model_2}
model_2 <- "
  # Single factor
  Curiosity =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight + Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo + Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

fit_2 = cfa(model_2, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")

summary(fit_2, standardized = TRUE, fit.measures = TRUE)
```




## Manipulation Check
```{r}
semTools::net(fit_1,fit_2)
```

## Confirmatory Analysis
```{r}
lavaan::lavTestLRT(fit_1, fit_2)
```


## Exploratory Analysis

```{r}
model_3 <- "
  # Higher-order factor
  Curiosty =~ Insight_seeking + Explo_curiosity + Morbid_curiosity
  
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  Morbid_curiosity =~ Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
"

model_4 <- "
  # Single factor
  Curiosity =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight + Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo + Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
"

model_5 <- "
  # Media specific factors
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

model_6 <- "
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  Morbid_curiosity =~ Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

fit_3 = cfa(model_3, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")
fit_4 = cfa(model_4, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")
fit_5 = cfa(model_5, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")
fit_6 = cfa(model_6, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")

```


```{r}
library(nonnest2) # comparing non-nested models

nonnest2::vuongtest(fit_1, fit_6)

nonnest2::icci(fit_1, fit_6)
```


```{r not presented}
# create a subset without morbid curiosity, to test if our model is still better than the alternative

data_2_cfa_2 = data_2_cfa %>%
  select(starts_with("Novel"), starts_with("Movie"), starts_with("Nonfict"), starts_with("Game"), starts_with("Docu")) %>%
  select(-contains("morbid")) %>%
  lapply(as.numeric) %>%
  as.data.frame()

data_2_cfa_2$ResponseId = data_2_cfa$ResponseId

model_7 <- "
  # Higher-order factor
  Curiosty =~ Insight_seeking + Explo_curiosity
  
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo
  Movies =~ Movie_insight + Movie_explo
  Nonfict =~ Nonfict_insight + Nonfict_explo
  Games =~ Game_insight + Game_explo
  Docu =~ Docu_insight + Docu_explo
  "

model_8 <- "
  # Single factor
  Curiosity =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight + Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo
  Movies =~ Movie_insight + Movie_explo
  Nonfict =~ Nonfict_insight + Nonfict_explo
  Games =~ Game_insight + Game_explo
  Docu =~ Docu_insight + Docu_explo
  "

fit_7 = cfa(model_7, data = data_2_cfa_2, missing = "FIML", optim.method = "BFGS")
fit_8 = cfa(model_8, data = data_2_cfa_2, missing = "FIML", optim.method = "BFGS")
```

```{r}
summary(fit_7, standardized = TRUE, fit.measures = TRUE)
summary(fit_8, standardized = TRUE, fit.measures = TRUE)
```

```{r}
lavaan::lavTestLRT(fit_7, fit_8)
```



