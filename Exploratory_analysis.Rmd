---
title: "Analysis Paper Cluster Insight"
date: "2024-04-03"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
header-includes:
  - \usepackage{placeins}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results = 'asis')
# Set options for kableExtra
options(knitr.table.format = "latex")
```

```{r library}
library(tidyverse)
library(kableExtra)
library(jtools)
```

# Study 1

```{r}
# Prepare dataset and demographics

data_1 = read_csv("Data/Study1_data.csv")

# Suppress people who did not understand explanation of insight
data_1 = data_1 %>% filter(Q6 == 2)

# Select columns with ratings of enjoyment and transform in numeric
media_columns = c("Novel_enjoy", "Movie_enjoy", "Science_enjoy", "Puzzle_enjoy", "Game_enjoy", "Docu_enjoy")
media_ratings = data_1[media_columns]
media_ratings[] <- lapply(media_ratings, function(x) as.numeric(as.character(x)))

media_columns_frequency = c("Novel_regularity", "Movie_regularity", "Science_regularity", "Puzzle_regularity", "Game_regularity", "Docu_regularity")
media_frequency = data_1[media_columns_frequency]
media_frequency[] <- lapply(media_frequency, function(x) as.numeric(as.character(x)))

# Demographics
demo_1 = read_csv("Data/Study1_demo.csv")
demo_1$PROLIFIC_PID = demo_1[["Participant id"]]

# Merge datasets
data_1 = left_join(data_1, demo_1, by = "PROLIFIC_PID")

# Summary stats of participants
table(data_1$Sex)
mean(as.numeric(data_1$Age), na.rm = TRUE)
sd(data_1$Age, na.rm = TRUE)

```


## Descriptive Statistics

```{r}
media_ratings %>%
  gather(key = "media", value = "rating") %>%
  group_by(media) %>%
  summarise(mean = mean(rating, na.rm = TRUE), sd = sd(rating, na.rm = TRUE), n_NA = sum(is.na(rating))) %>%
  kable()
```

```{r}
media_frequency %>%
  gather(key = "media", value = "frequency") %>%
  group_by(media) %>%
  summarise(mean = mean(frequency, na.rm = TRUE), sd = sd(frequency, na.rm = TRUE), n_NA = sum(is.na(frequency))) %>%
  kable()
```



## Confirmatory Analyses

**H1**: The mean of all pairwise correlations will be significantly different from chance

```{r}
# Calculate pairwise correlations
cor_matrix <- cor(media_ratings, use="pairwise.complete.obs")

# Extract lower triangle without the diagonal
cor_values <- cor_matrix[lower.tri(cor_matrix)]

# Calculate mean of these correlation coefficients
mean_cor <- mean(cor_values)
sd_mean_cor = sd(cor_values)

# Loop through the matrix to extract lower triangle correlations
correlation_table <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
var_names <- colnames(media_ratings)

for (i in 1:(length(var_names)-1)) {
  for (j in (i+1):length(var_names)) {
    pair <- sort(c(var_names[i], var_names[j]))
    pair_name <- paste(pair[1], pair[2], sep="-")
    
    cor_value <- cor_matrix[i, j]
    
    correlation_table <- rbind(correlation_table, data.frame(Pair = pair_name, Correlation = cor_value))
  }
}

rm(cor_value, cor_values, i, j, pair, pair_name, var_names)
```

```{r plot}
# plot the correlation matrix with a heatmap with the value of correlations
cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column(var = "media") %>%
  gather(key = "media2", value = "correlation", -media) %>%
  ggplot(aes(x = media, y = media2, fill = correlation)) +
  geom_tile() +
  geom_text(aes(label = round(correlation, 2))) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Correlation matrix of media ratings", x = "Media 1", y = "Media 2", fill = "Correlation") +
  theme(legend.position = "right") 
```


```{r Bootstrapping}

# Bootstrapping ####

set.seed(123)  # Ensuring reproducibility

n_iterations <- 1000 

# Initialize an empty data frame to store the results from all iterations
all_bootstrap_results <- data.frame(Iteration = integer(), Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)

for (i in 1:n_iterations) {
  # Randomize dataset: shuffle the ratings within each column
  randomized_data <- as.data.frame(lapply(media_ratings, sample))
  
  # Temporary storage for this iteration's results
  iteration_results <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
  
  var_names <- colnames(randomized_data)
  
  # Compute pairwise correlations
  for (m in 1:(length(var_names)-1)) {
    for (n in (m+1):length(var_names)) {
      # Ensure pair names are always in alphabetical order
      pair <- sort(c(var_names[m], var_names[n]))
      pair_name <- paste(pair[1], pair[2], sep="-")
      
      cor_value <- cor(randomized_data[[m]], randomized_data[[n]], use="pairwise.complete.obs")
      
      # Temporarily store the pair, its correlation, and iteration number
      iteration_results <- rbind(iteration_results, data.frame(Pair = pair_name, Correlation = cor_value))
    }
  }
  
  # Add iteration number to the iteration_results
  iteration_results$Iteration <- i
  
  # Combine this iteration's results with the main storage
  all_bootstrap_results <- rbind(all_bootstrap_results, iteration_results)
}

rm(n, n_iterations, pair, pair_name, var_names, m, i, cor_value, randomized_data)

```

```{r Pre-registered test}
# Aggregate bootstrap results to find mean correlation per iteration
bootstrap_means <- all_bootstrap_results %>%
  group_by(Iteration) %>%
  summarise(MeanCorrelation = mean(Correlation, na.rm = TRUE))

# Calculate the 95% confidence interval for the bootstrap means
bootstrap_ci <- quantile(bootstrap_means$MeanCorrelation, probs = c(0.025, 0.975), na.rm = TRUE)

# Assuming mean_cor is the mean of actual correlations from correlation_table
is_significantly_higher <- mean_cor > bootstrap_ci[2]  # Check if higher than upper CI bound

# Print the result
print(paste("Is the actual mean correlation significantly higher? ", is_significantly_higher))
```

```{r}
ggplot(bootstrap_means, aes(x = MeanCorrelation)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(xintercept = bootstrap_ci[1], linetype = "dashed", color = "grey", size = 1) +  # Lower CI bound
  geom_vline(xintercept = bootstrap_ci[2], linetype = "dashed", color = "grey", size = 1) +  # Upper CI bound
  geom_vline(xintercept = mean_cor, color = ifelse(is_significantly_higher, "green", "red"), size = 1.5) +  # Actual mean correlation
  theme_minimal() +
  labs(title = "Distribution of Bootstrap Mean Correlations",
       x = "Mean Correlation",
       y = "Count") +
  annotate("text", x = mean_cor, y = Inf, label = sprintf("Actual mean: %.3f", mean_cor), vjust = 2, hjust=1)
```


## Exploratory Analyses

```{r Analyses Plot for each pairs}

# Assuming correlation_table contains the actual data correlations
# And mean_cor is the mean of these correlations

# Create a data frame for the vertical lines
vlines_data <- correlation_table

# Assign unique colors to each pair (and the mean score)
vlines_data$Color <- factor(vlines_data$Pair)

# Specify colors manually if preferred, or use a color palette
# This example uses a palette for demonstration; replace with your desired colors
num_colors <- length(unique(vlines_data$Color))
palette <- hcl.colors(num_colors, "Viridis")
names(palette) <- levels(vlines_data$Color)

ggplot(all_bootstrap_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black") +
  geom_vline(data = vlines_data, aes(xintercept = Correlation, color = Color), size = 1) +  # Vertical lines for each pair
  geom_vline(xintercept = mean_cor, color = "red", size = 2) +  # Larger line for mean score
  scale_color_manual(values = palette) +  # Apply the color palette
  theme_minimal() +
  labs(title = "Distribution of Correlations from Bootstrap Analysis compared to actual distribution of correlations",
       x = "Correlation",
       y = "Count",
       color = "Pair") +  # Legend title
  theme(legend.position = "right")
```

**RQ1**: What pairwise correlations across media are significantly different from chance?

```{r Test by Media Association}
# Calculate 95% Confidence Intervals for each Pair
bootstrap_cis <- all_bootstrap_results %>%
  group_by(Pair) %>%
  summarise(Lower = quantile(Correlation, 0.025, na.rm = TRUE),
            Upper = quantile(Correlation, 0.975, na.rm = TRUE))

# Merge the actual correlations with their corresponding CIs
comparison_table <- merge(correlation_table, bootstrap_cis, by = "Pair")

# Determine if actual correlations are significantly higher
comparison_table$Significantly_Higher <- with(comparison_table, Correlation > Upper)


# Merge the actual correlations with their CIs for plotting
vlines_with_cis <- merge(vlines_data, bootstrap_cis, by = "Pair", all.x = TRUE)

# Ensure this flag is included in vlines_with_cis for coloring
vlines_with_cis <- merge(vlines_with_cis, comparison_table[, c("Pair", "Significantly_Higher")], by = "Pair")

# Add a 'Color' column based on significance for plotting
vlines_with_cis$Color <- ifelse(vlines_with_cis$Significantly_Higher, "green", "red")

# Plotting with confidence intervals
ggplot(all_bootstrap_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(data = vlines_with_cis, aes(xintercept = Correlation, color = Color), size = 1) +  # Color based on significance
  geom_vline(data = vlines_with_cis, aes(xintercept = Lower), linetype = "dotted", size = 0.5, color = "gray") +  # CI lower bound in gray
  geom_vline(data = vlines_with_cis, aes(xintercept = Upper), linetype = "dotted", size = 0.5, color = "gray") +  # CI upper bound in gray
  facet_wrap(~ Pair, scales = "free_x") +
  scale_color_identity() +  # Use actual color names provided in the data
  theme_minimal() +
  labs(title = "Distribution of Bootstrapped Correlations by Pair",
       x = "Correlation",
       y = "Count") +
  theme(legend.position = "none")  # No legend needed as colors are self-explanatory

```
**RQ2**: Is childhood SES related to how much participants enjoy insightful materials?

```{r}
media_ratings$mean_enjoyment = rowMeans(media_ratings, na.rm = TRUE)

data_1$mean_enjoyment = media_ratings$mean_enjoyment

data_1$SES_Child_1 = as.numeric(data_1$SES_Child_1)
data_1$SES_Child_2 = as.numeric(data_1$SES_Child_2)
data_1$SES_Child_3 = as.numeric(data_1$SES_Child_3)

data_1$mean_child_SES = rowMeans(data_1[, c("SES_Child_1", "SES_Child_2", "SES_Child_3")], na.rm = TRUE)

S1_rq2 = lm(mean_enjoyment ~ mean_child_SES, data = data_1)

export_summs(S1_rq2, model.names = c("Mean Enjoyment"))
```
\FloatBarrier

**RQ3.** Is current SES related to how much participants enjoy insightful materials?

```{r}

data_1$SES_Now_1 = as.numeric(data_1$SES_Now_1)
data_1$SES_Now_2 = as.numeric(data_1$SES_Now_2)
data_1$SES_Now_3 = as.numeric(data_1$SES_Now_3)

data_1$mean_now_SES = rowMeans(data_1[, c("SES_Now_1", "SES_Now_2", "SES_Now_3")], na.rm = TRUE)

S1_rq3 = lm(mean_enjoyment ~ mean_now_SES, data = data_1)

export_summs(S1_rq3, model.names = c("Mean Enjoyment"))
```

**RQ4.** Is age related to how much participants enjoy insightful materials?

```{r}
data_1$age = as.numeric(data_1$age)

S1_rq4 = lm(mean_enjoyment ~ scale(age), data = data_1)

export_summs(S1_rq4, model.names = c("Mean Enjoyment"))
```

```{r}
summary(S1_rq4)
```

```{r Rain cloud plot plots}
media_ratings_long = media_ratings %>% 
  gather(key = "media", value = "rating") %>% 
  filter(!is.na(rating))

ggplot(media_ratings_long, aes(y = rating, x = media)) +
  ggdist::stat_halfeye(
    adjust = 2, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    fill = "#9FE2BF"
  )  +
  geom_boxplot(
    width = .25, 
    outlier.shape = NA,
    fill = "#9FE2BF"
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter(seed = 1, width = .1),
    fill = "#9FE2BF"
  ) + 
  ylab("Enjoyment") +
  xlab("") +
  coord_cartesian(xlim = c(1.2, NA), clip = "off") +
  theme_minimal()

```

**RQ5**: Is there a cluster of people who never like insight stimuli?

```{r}

data_1$never_like = rowSums(select(media_ratings, -Puzzle_enjoy) < 4, na.rm = TRUE)

ggplot(data_1, aes(x = never_like)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.5) +
  labs(title = "Distribution of Number of Media Categories where insight is not enjoyed (<4)",
       x = "Number of Media Categories",
       y = "Count") +
  theme_minimal()

```


# Analysis with Klopfenstein data

```{r Exploratory Analysis with Klopenstein data}

data_Klopfenstein = read_csv("Data/Study4_Klopfenstein_2024.csv")
stim_K = read_csv("Data/Stim_Klopfenstein_2024_with_topics.csv")

# correct index Stim_k

stim_K$explanation_id = 1:nrow(stim_K)

data_Klopfenstein = merge(data_Klopfenstein, stim_K, by = c("explanation_id"), how = "left")

library(lmerTest)
summary(lmer(appeal ~insight + (1|participant_id), data = data_Klopfenstein))

```

```{r}
ggplot(data_Klopfenstein, aes(x = insight, y = appeal, group = topic_name, color = topic_name)) +
  geom_jitter(width = 0.1, height = 0.1, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Insight and Appeal",
       x = "Insight",
       y = "Appeal") +
  theme_minimal()
```

```{r}

summary(lmer(appeal ~ insight*factor(topic_name) + (1|participant_id), data = data_Klopfenstein))

```

```{r}
data_Klopfenstein %>%
  group_by(topic_name) %>%
  summarize(mean_insight = mean(insight),
            sd_insight = sd(insight),
            mean_appeal = mean(appeal),
            sd_appeal = sd(appeal))
```

```{r}
ggplot(data_Klopfenstein, aes(x = insight, y = appeal, group = participant_id, color = participant_id)) +
  geom_jitter(width = 0.05, height = 0.05, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Insight and Appeal",
       x = "Insight",
       y = "Appeal") +
  theme_minimal() +
  guides(color = FALSE)
```

```{r}
slopes = data_Klopfenstein %>%
  group_by(participant_id) %>%
  summarize(slope = lm(appeal ~ insight)$coefficients[2],
            intercept = lm(appeal ~ insight)$coefficients[1])

ggplot(slopes, aes(x = slope)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Slopes by participants",
       x = "Slope",
       y = "Frequence")

```

```{r}
cor(slopes$intercept, slopes$slope, use = "complete.obs")
```
```{r}
slopes_topic = data_Klopfenstein %>%
  group_by(topic_name) %>%
  sample_n(10) %>% 
  summarize(slope = lm(appeal ~ insight)$coefficients[2],
            intercept = lm(appeal ~ insight)$coefficients[1])
```


```{r}
ggplot(slopes_topic, aes(x = slope)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Slopes by topics",
       x = "Slope",
       y = "Frequence")
```


```{r}
participants_with_low_slopes = slopes %>%
  filter(slope < 0.3)

data_Klopfenstein %>%
  filter(participant_id %in% participants_with_low_slopes$participant_id) %>%
  ggplot(aes(x = insight, y = appeal, group = participant_id, color = participant_id)) +
    geom_jitter(width = 0.05, height = 0.05, alpha = 0.6) +
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = "Relationship between Insight and Appeal for slopes < .3",
         x = "Insight",
         y = "Appeal") +
    theme_minimal() +
    guides(color = FALSE)

```

```{r}
# create quartiles based on the slope

slopes$quartile = cut(slopes$slope, breaks = quantile(slopes$slope, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), include.lowest = TRUE, )

# box plot of appeal depending on the quartile

data_Klopfenstein %>%
  left_join(slopes, by = "participant_id") %>%
  drop_na() %>%
  ggplot(aes(x = quartile, y = appeal, group = quartile, color = quartile)) +
    geom_boxplot() +
    labs(title = "Appeal by quartile of slope",
         x = "Quartile",
         y = "Appeal") +
    theme_minimal()

```

# Simulation to test CFA modelling

```{r}
library(lavaan)
library(semTools)
```

```{r}

model_1 <- "
  # Higher-order factor
  Curiosty =~ IW_seeking + Insight_seeking + Horror_seeking
  
  # First-order factors
  IW_seeking =~ IW_docu + IW_games + IW_non_fiction + IW_films + IW_novels
  Insight_seeking =~ Insight_docu + Insight_games + Insight_non_fiction + Insight_films + Insight_novels
  Horror_seeking =~ Horror_docu + Horror_games + Horror_non_fiction + Horror_films + Horror_novels
  
  # Control for media specific effect
  docu =~ IW_docu + Insight_docu + Horror_docu
  games =~ IW_games + Insight_games + Horror_games
  non_fiction =~ IW_non_fiction + Insight_non_fiction + Horror_non_fiction
  films =~ IW_films + Insight_films + Horror_films
  novels =~ IW_novels + Insight_novels + Horror_novels
"

model_2 = "
  # Single factor
  Curiosity =~ IW_docu + IW_games + IW_non_fiction + IW_films + IW_novels + Insight_docu + Insight_games + Insight_non_fiction + Insight_films + Insight_novels + Horror_docu + Horror_games + Horror_non_fiction + Horror_films + Horror_novels
  
  # Control for media specific effect
  docu =~ IW_docu + Insight_docu + Horror_docu
  games =~ IW_games + Insight_games + Horror_games
  non_fiction =~ IW_non_fiction + Insight_non_fiction + Horror_non_fiction
  films =~ IW_films + Insight_films + Horror_films
  novels =~ IW_novels + Insight_novels + Horror_novels
  
"

model_3 = "
  # Higher-order factor
  Curiosty =~ IW_seeking + Insight_seeking + Horror_seeking
  
  # First-order factors
  IW_seeking =~ IW_docu + IW_games + IW_non_fiction + IW_films + IW_novels
  Insight_seeking =~ Insight_docu + Insight_games + Insight_non_fiction + Insight_films + Insight_novels
  Horror_seeking =~ Horror_docu + Horror_games + Horror_non_fiction + Horror_films + Horror_novels
"

model_4 = "
  # Single factor
  Curiosity =~ IW_docu + IW_games + IW_non_fiction + IW_films + IW_novels + Insight_docu + Insight_games + Insight_non_fiction + Insight_films + Insight_novels + Horror_docu + Horror_games + Horror_non_fiction + Horror_films + Horror_novels
  
"

# test_model = "
#   # Higher-order factors
#   Curiosity =~ IW_seeking + Insight_seeking
# 
# 
#   # First-order factors
#   IW_seeking =~ IW_docu + IW_games + IW_non_fiction + IW_films + IW_novels
#   Insight_seeking =~ Insight_docu + Insight_games + Insight_non_fiction + Insight_films + Insight_novels
#   Horror_seeking =~ Horror_docu + Horror_games + Horror_non_fiction + Horror_films + Horror_novels
#   
#   # Control for media specific effect
#   docu =~ IW_docu + Insight_docu + Horror_docu
#   games =~ IW_games + Insight_games + Horror_games
#   non_fiction =~ IW_non_fiction + Insight_non_fiction + Horror_non_fiction
#   films =~ IW_films + Insight_films + Horror_films
#   novels =~ IW_novels + Insight_novels + Horror_novels
# "

model_structure_strong_curiosity <- '
# General Curiosity factor with varied loadings to avoid multicollinearity
Curiosity =~ 0.6*IW_docu + 0.7*IW_games + 0.8*IW_non_fiction + 0.9*IW_films + 0.75*IW_novels + 
              0.65*Insight_docu + 0.85*Insight_games + 0.7*Insight_non_fiction + 0.8*Insight_films + 0.9*Insight_novels +
              0.9*Horror_docu + 0.75*Horror_games + 0.8*Horror_non_fiction + 0.85*Horror_films + 0.7*Horror_novels

# Specific seeking factors with variability to reflect distinct constructs
IW_seeking =~ 0.5*IW_docu + 0.6*IW_games + 0.7*IW_non_fiction + 0.8*IW_films + 0.65*IW_novels
Insight_seeking =~ 0.6*Insight_docu + 0.7*Insight_games + 0.5*Insight_non_fiction + 0.65*Insight_films + 0.75*Insight_novels
Horror_seeking =~ 0.7*Horror_docu + 0.8*Horror_games + 0.6*Horror_non_fiction + 0.5*Horror_films + 0.65*Horror_novels

# Media-specific latent variables to account for method effect with moderate loadings
docu =~ 0.5*IW_docu + 0.55*Insight_docu + 0.6*Horror_docu
games =~ 0.6*IW_games + 0.65*Insight_games + 0.5*Horror_games
non_fiction =~ 0.55*IW_non_fiction + 0.5*Insight_non_fiction + 0.65*Horror_non_fiction
films =~ 0.6*IW_films + 0.55*Insight_films + 0.5*Horror_films
novels =~ 0.5*IW_novels + 0.6*Insight_novels + 0.55*Horror_novels
'

# Simulating the data based model 1
set.seed(230)  
sim_data <- simulateData(model_1, sample.nobs = 500, model.type = "cfa")

n = 500
# Simulate a fully random dataset
fully_random_data = data.frame(
  IW_docu = rnorm(n, mean = 4, sd = 1),
  IW_games = rnorm(n, mean = 4, sd = 1),
  IW_non_fiction = rnorm(n, mean = 4, sd = 1),
  IW_films = rnorm(n, mean = 4, sd = 1),
  IW_novels = rnorm(n, mean = 4, sd = 1),
  Insight_docu = rnorm(n, mean = 4, sd = 1),
  Insight_games = rnorm(n, mean = 4, sd = 1),
  Insight_non_fiction = rnorm(n, mean = 4, sd = 1),
  Insight_films = rnorm(n, mean = 4, sd = 1),
  Insight_novels = rnorm(n, mean = 4, sd = 1),
  Horror_docu = rnorm(n, mean = 4, sd = 1),
  Horror_games = rnorm(n, mean = 4, sd = 1),
  Horror_non_fiction = rnorm(n, mean = 4, sd = 1),
  Horror_films = rnorm(n, mean = 4, sd = 1),
  Horror_novels = rnorm(n, mean = 4, sd = 1)
)

# Fit the model 1
fit_model_1 = cfa(model_1, data = sim_data, estimator = "ML")

fit_model_2 = cfa(model_2, data = sim_data, estimator = "ML")

fit_model_3 = cfa(model_3, data = sim_data, estimator = "ML")

fit_model_4 = cfa(model_4, data = sim_data, estimator = "ML")

# test_model_3 = cfa(test_model, data = sim_data)

```


```{r}
semTools::net(fit_model_1, fit_model_2, fit_model_3, fit_model_4)
```



```{r}
summary(fit_model_2)
```

```{r}
summary(fit_model_3)
```

```{r}
summary(fit_model_4)
```



```{r}
semTools::net(fit_model_3, fit_model_4)
```

```{r}
library(nonnest2)

nonnest2::vuongtest(fit_model_3, fit_model_4, nested = TRUE)
```


```{r}
summary(semTools::compareFit(fit_model_1, fit_model_2))
```



```{r}
print(lavTestLRT(fit_model_3, fit_model_4))
```


```{r}
fitMeasures(fit_model_1, c("cfi", "rmsea", "srmr", "aic", "bic"))
```
```{r}
fitMeasures(fit_model_2, c("cfi", "rmsea", "srmr", "aic", "bic"))
```

```{r}
fitMeasures(test_model_3, c("cfi", "rmsea", "srmr", "aic", "bic"))
```

```{r}
anova(fit_model_1, test_model_3)
```

```{r}
nonnest2::vuongtest(fit_model_1, fit_model_2, nested = FALSE)
```


# Test ONE-factor CFA on previous data

```{r}
single_factor = "
  Insight_seeking =~ Novel_enjoy + Movie_enjoy + Game_enjoy + Docu_enjoy + Science_enjoy + Puzzle_enjoy
"

alternative_model = "
  Insight_seeking =~ Novel_enjoy + Movie_enjoy + Game_enjoy + Puzzle_enjoy
  Nerd =~ Science_enjoy + Docu_enjoy
  
"

second_alternative_model = 
  "
  Insight_seeking =~ Novel_enjoy + Game_enjoy
  Screen_addict =~ Movie_enjoy + Docu_enjoy
  Others =~ Puzzle_enjoy + Science_enjoy
  "

fit_single_factor = cfa(single_factor, data = media_ratings, estimator = "ML")
fit_alternative_model = cfa(alternative_model, data = media_ratings, estimator = "ML")
fit_second_alternative_model = cfa(second_alternative_model, data = media_ratings, estimator = "ML")

```



```{r}
semTools::net(fit_single_factor, fit_alternative_model, fit_second_alternative_model)
```

```{r}
fitmeasures(fit_alternative_model, c("cfi", "rmsea", "srmr", "aic", "bic"))
```

```{r}
fitMeasures(fit_single_factor, c("cfi", "rmsea", "srmr", "aic", "bic"))
```

```{r}
fitMeasures(fit_second_alternative_model, c("cfi", "rmsea", "srmr", "aic", "bic"))
```

```{r}
summary(compareFit(fit_single_factor, fit_second_alternative_model))
```


