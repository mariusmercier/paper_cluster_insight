---
title: "Analysis Paper Cluster Insight"
date: "2024-04-03"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
header-includes:
  - \usepackage{placeins}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results = 'asis')
# Set options for kableExtra
options(knitr.table.format = "latex")
```

```{r library}
library(tidyverse)
library(kableExtra)
library(jtools)
library(lavaan)
library(semTools)
```

# Study 1

```{r}
# Prepare dataset and demographics

data_1 = read_csv("Data/Study1_data.csv")

# Suppress people who did not understand explanation of insight
data_1 = data_1 %>% filter(Q6 == 2)

# Select columns with ratings of enjoyment and transform in numeric
media_columns = c("Novel_enjoy", "Movie_enjoy", "Science_enjoy", "Puzzle_enjoy", "Game_enjoy", "Docu_enjoy")
media_ratings = data_1[media_columns]
media_ratings[] <- lapply(media_ratings, function(x) as.numeric(as.character(x)))

media_columns_frequency = c("Novel_regularity", "Movie_regularity", "Science_regularity", "Puzzle_regularity", "Game_regularity", "Docu_regularity")
media_frequency = data_1[media_columns_frequency]
media_frequency[] <- lapply(media_frequency, function(x) as.numeric(as.character(x)))

# Demographics
demo_1 = read_csv("Data/Study1_demo.csv")
demo_1$PROLIFIC_PID = demo_1[["Participant id"]]

# Merge datasets
data_1 = left_join(data_1, demo_1, by = "PROLIFIC_PID")

# Summary stats of participants
table(data_1$Sex)
mean(as.numeric(data_1$Age), na.rm = TRUE)
sd(data_1$Age, na.rm = TRUE)

```


## Descriptive Statistics

```{r}
media_ratings %>%
  gather(key = "media", value = "rating") %>%
  group_by(media) %>%
  summarise(mean = mean(rating, na.rm = TRUE), sd = sd(rating, na.rm = TRUE), n_NA = sum(is.na(rating))) %>%
  kable()
```

```{r}
media_frequency %>%
  gather(key = "media", value = "frequency") %>%
  group_by(media) %>%
  summarise(mean = mean(frequency, na.rm = TRUE), sd = sd(frequency, na.rm = TRUE), n_NA = sum(is.na(frequency))) %>%
  kable()
```



## Confirmatory Analyses

**H1**: The mean of all pairwise correlations will be significantly different from chance

```{r}
# Calculate pairwise correlations
cor_matrix <- cor(media_ratings, use="pairwise.complete.obs")

# Extract lower triangle without the diagonal
cor_values <- cor_matrix[lower.tri(cor_matrix)]

# Calculate mean of these correlation coefficients
mean_cor <- mean(cor_values)
sd_mean_cor = sd(cor_values)

# Loop through the matrix to extract lower triangle correlations
correlation_table <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
var_names <- colnames(media_ratings)

for (i in 1:(length(var_names)-1)) {
  for (j in (i+1):length(var_names)) {
    pair <- sort(c(var_names[i], var_names[j]))
    pair_name <- paste(pair[1], pair[2], sep="-")
    
    cor_value <- cor_matrix[i, j]
    
    correlation_table <- rbind(correlation_table, data.frame(Pair = pair_name, Correlation = cor_value))
  }
}

rm(cor_value, cor_values, i, j, pair, pair_name, var_names)
```

```{r plot}
# plot the correlation matrix with a heatmap with the value of correlations
cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column(var = "media") %>%
  gather(key = "media2", value = "correlation", -media) %>%
  ggplot(aes(x = media, y = media2, fill = correlation)) +
  geom_tile() +
  geom_text(aes(label = round(correlation, 2))) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Correlation matrix of media ratings", x = "Media 1", y = "Media 2", fill = "Correlation") +
  theme(legend.position = "right") 
```


```{r Bootstrapping}

# Bootstrapping ####

set.seed(123)  # Ensuring reproducibility

n_iterations <- 1000 

# Initialize an empty data frame to store the results from all iterations
all_bootstrap_results <- data.frame(Iteration = integer(), Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)

for (i in 1:n_iterations) {
  # Randomize dataset: shuffle the ratings within each column
  randomized_data <- as.data.frame(lapply(media_ratings, sample))
  
  # Temporary storage for this iteration's results
  iteration_results <- data.frame(Pair = character(), Correlation = numeric(), stringsAsFactors = FALSE)
  
  var_names <- colnames(randomized_data)
  
  # Compute pairwise correlations
  for (m in 1:(length(var_names)-1)) {
    for (n in (m+1):length(var_names)) {
      # Ensure pair names are always in alphabetical order
      pair <- sort(c(var_names[m], var_names[n]))
      pair_name <- paste(pair[1], pair[2], sep="-")
      
      cor_value <- cor(randomized_data[[m]], randomized_data[[n]], use="pairwise.complete.obs")
      
      # Temporarily store the pair, its correlation, and iteration number
      iteration_results <- rbind(iteration_results, data.frame(Pair = pair_name, Correlation = cor_value))
    }
  }
  
  # Add iteration number to the iteration_results
  iteration_results$Iteration <- i
  
  # Combine this iteration's results with the main storage
  all_bootstrap_results <- rbind(all_bootstrap_results, iteration_results)
}

rm(n, n_iterations, pair, pair_name, var_names, m, i, cor_value, randomized_data)

```

```{r Pre-registered test}
# Aggregate bootstrap results to find mean correlation per iteration
bootstrap_means <- all_bootstrap_results %>%
  group_by(Iteration) %>%
  summarise(MeanCorrelation = mean(Correlation, na.rm = TRUE))

# Calculate the 95% confidence interval for the bootstrap means
bootstrap_ci <- quantile(bootstrap_means$MeanCorrelation, probs = c(0.025, 0.975), na.rm = TRUE)

# Assuming mean_cor is the mean of actual correlations from correlation_table
is_significantly_higher <- mean_cor > bootstrap_ci[2]  # Check if higher than upper CI bound

# Print the result
print(paste("Is the actual mean correlation significantly higher? ", is_significantly_higher))
```

```{r}
ggplot(bootstrap_means, aes(x = MeanCorrelation)) +
  geom_histogram(binwidth = 0.01, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(xintercept = bootstrap_ci[1], linetype = "dashed", color = "grey", size = 1) +  # Lower CI bound
  geom_vline(xintercept = bootstrap_ci[2], linetype = "dashed", color = "grey", size = 1) +  # Upper CI bound
  geom_vline(xintercept = mean_cor, color = ifelse(is_significantly_higher, "green", "red"), size = 1.5) +  # Actual mean correlation
  theme_minimal() +
  labs(title = "Distribution of Bootstrap Mean Correlations",
       x = "Mean Correlation",
       y = "Count") +
  annotate("text", x = mean_cor, y = Inf, label = sprintf("Actual mean: %.3f", mean_cor), vjust = 2, hjust=1)
```


## Exploratory Analyses

```{r Analyses Plot for each pairs}

# Assuming correlation_table contains the actual data correlations
# And mean_cor is the mean of these correlations

# Create a data frame for the vertical lines
vlines_data <- correlation_table

# Assign unique colors to each pair (and the mean score)
vlines_data$Color <- factor(vlines_data$Pair)

# Specify colors manually if preferred, or use a color palette
# This example uses a palette for demonstration; replace with your desired colors
num_colors <- length(unique(vlines_data$Color))
palette <- hcl.colors(num_colors, "Viridis")
names(palette) <- levels(vlines_data$Color)

ggplot(all_bootstrap_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black") +
  geom_vline(data = vlines_data, aes(xintercept = Correlation, color = Color), size = 1) +  # Vertical lines for each pair
  geom_vline(xintercept = mean_cor, color = "red", size = 2) +  # Larger line for mean score
  scale_color_manual(values = palette) +  # Apply the color palette
  theme_minimal() +
  labs(title = "Distribution of Correlations from Bootstrap Analysis compared to actual distribution of correlations",
       x = "Correlation",
       y = "Count",
       color = "Pair") +  # Legend title
  theme(legend.position = "right")
```

**RQ1**: What pairwise correlations across media are significantly different from chance?

```{r Test by Media Association}
# Calculate 95% Confidence Intervals for each Pair
bootstrap_cis <- all_bootstrap_results %>%
  group_by(Pair) %>%
  summarise(Lower = quantile(Correlation, 0.025, na.rm = TRUE),
            Upper = quantile(Correlation, 0.975, na.rm = TRUE))

# Merge the actual correlations with their corresponding CIs
comparison_table <- merge(correlation_table, bootstrap_cis, by = "Pair")

# Determine if actual correlations are significantly higher
comparison_table$Significantly_Higher <- with(comparison_table, Correlation > Upper)


# Merge the actual correlations with their CIs for plotting
vlines_with_cis <- merge(vlines_data, bootstrap_cis, by = "Pair", all.x = TRUE)

# Ensure this flag is included in vlines_with_cis for coloring
vlines_with_cis <- merge(vlines_with_cis, comparison_table[, c("Pair", "Significantly_Higher")], by = "Pair")

# Add a 'Color' column based on significance for plotting
vlines_with_cis$Color <- ifelse(vlines_with_cis$Significantly_Higher, "green", "red")

# Plotting with confidence intervals
ggplot(all_bootstrap_results, aes(x = Correlation)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.5) +
  geom_vline(data = vlines_with_cis, aes(xintercept = Correlation, color = Color), size = 1) +  # Color based on significance
  geom_vline(data = vlines_with_cis, aes(xintercept = Lower), linetype = "dotted", size = 0.5, color = "gray") +  # CI lower bound in gray
  geom_vline(data = vlines_with_cis, aes(xintercept = Upper), linetype = "dotted", size = 0.5, color = "gray") +  # CI upper bound in gray
  facet_wrap(~ Pair, scales = "free_x") +
  scale_color_identity() +  # Use actual color names provided in the data
  theme_minimal() +
  labs(title = "Distribution of Bootstrapped Correlations by Pair",
       x = "Correlation",
       y = "Count") +
  theme(legend.position = "none")  # No legend needed as colors are self-explanatory

```
**RQ2**: Is childhood SES related to how much participants enjoy insightful materials?

```{r}
media_ratings$mean_enjoyment = rowMeans(media_ratings, na.rm = TRUE)

data_1$mean_enjoyment = media_ratings$mean_enjoyment

data_1$SES_Child_1 = as.numeric(data_1$SES_Child_1)
data_1$SES_Child_2 = as.numeric(data_1$SES_Child_2)
data_1$SES_Child_3 = as.numeric(data_1$SES_Child_3)

data_1$mean_child_SES = rowMeans(data_1[, c("SES_Child_1", "SES_Child_2", "SES_Child_3")], na.rm = TRUE)

S1_rq2 = lm(mean_enjoyment ~ mean_child_SES, data = data_1)

export_summs(S1_rq2, model.names = c("Mean Enjoyment"))
```
\FloatBarrier

**RQ3.** Is current SES related to how much participants enjoy insightful materials?

```{r}

data_1$SES_Now_1 = as.numeric(data_1$SES_Now_1)
data_1$SES_Now_2 = as.numeric(data_1$SES_Now_2)
data_1$SES_Now_3 = as.numeric(data_1$SES_Now_3)

data_1$mean_now_SES = rowMeans(data_1[, c("SES_Now_1", "SES_Now_2", "SES_Now_3")], na.rm = TRUE)

S1_rq3 = lm(mean_enjoyment ~ mean_now_SES, data = data_1)

export_summs(S1_rq3, model.names = c("Mean Enjoyment"))
```


```{r}
data_1$age = as.numeric(data_1$age)

S1_rq4 = lm(mean_enjoyment ~ scale(age), data = data_1)

export_summs(S1_rq4, model.names = c("Mean Enjoyment"))
```

```{r}
summary(S1_rq4)
```

```{r Rain cloud plot plots}
media_ratings_long = media_ratings %>% 
  gather(key = "media", value = "rating") %>% 
  filter(!is.na(rating))

ggplot(media_ratings_long, aes(y = rating, x = media)) +
  ggdist::stat_halfeye(
    adjust = 2, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA,
    fill = "#9FE2BF"
  )  +
  geom_boxplot(
    width = .25, 
    outlier.shape = NA,
    fill = "#9FE2BF"
  ) +
  geom_point(
    size = 1.3,
    alpha = .3,
    position = position_jitter(seed = 1, width = .1),
    fill = "#9FE2BF"
  ) + 
  ylab("Enjoyment") +
  xlab("") +
  coord_cartesian(xlim = c(1.2, NA), clip = "off") +
  theme_minimal()

```

**RQ5**: Is there a cluster of people who never like insight stimuli?

```{r}

data_1$never_like = rowSums(select(media_ratings, -Puzzle_enjoy) < 4, na.rm = TRUE)

ggplot(data_1, aes(x = never_like)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.5) +
  labs(title = "Distribution of Number of Media Categories where insight is not enjoyed (<4)",
       x = "Number of Media Categories",
       y = "Count") +
  theme_minimal()

```

```{r Exploratory Analysis with Klopenstein data}

data_Klopfenstein = read_csv("Data/Study4_Klopfenstein_2024.csv")
stim_K = read_csv("Data/Stim_Klopfenstein_2024_with_topics.csv")

# correct index Stim_k

stim_K$explanation_id = 1:nrow(stim_K)

data_Klopfenstein = merge(data_Klopfenstein, stim_K, by = c("explanation_id"), how = "left")

library(lmerTest)
summary(lmer(appeal ~insight + (1|participant_id), data = data_Klopfenstein))

```

```{r}
ggplot(data_Klopfenstein, aes(x = insight, y = appeal, group = topic_name, color = topic_name)) +
  geom_jitter(width = 0.1, height = 0.1, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Insight and Appeal",
       x = "Insight",
       y = "Appeal") +
  theme_minimal()
```

```{r}

summary(lmer(appeal ~ insight*factor(topic_name) + (1|participant_id), data = data_Klopfenstein))

```

```{r}
data_Klopfenstein %>%
  group_by(topic_name) %>%
  summarize(mean_insight = mean(insight),
            sd_insight = sd(insight),
            mean_appeal = mean(appeal),
            sd_appeal = sd(appeal))
```

```{r}
ggplot(data_Klopfenstein, aes(x = insight, y = appeal, group = participant_id, color = participant_id)) +
  geom_jitter(width = 0.05, height = 0.05, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Insight and Appeal",
       x = "Insight",
       y = "Appeal") +
  theme_minimal() +
  guides(color = FALSE)
```

```{r}
slopes = data_Klopfenstein %>%
  group_by(participant_id) %>%
  summarize(slope = lm(appeal ~ insight)$coefficients[2],
            intercept = lm(appeal ~ insight)$coefficients[1])

ggplot(slopes, aes(x = slope)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Slopes by participants",
       x = "Slope",
       y = "Frequence")

```

```{r}
cor(slopes$intercept, slopes$slope, use = "complete.obs")
```
```{r}
slopes_topic = data_Klopfenstein %>%
  group_by(topic_name) %>%
  sample_n(10) %>% 
  summarize(slope = lm(appeal ~ insight)$coefficients[2],
            intercept = lm(appeal ~ insight)$coefficients[1])
```


```{r}
ggplot(slopes_topic, aes(x = slope)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Slopes by topics",
       x = "Slope",
       y = "Frequence")
```


```{r}
participants_with_low_slopes = slopes %>%
  filter(slope < 0.3)

data_Klopfenstein %>%
  filter(participant_id %in% participants_with_low_slopes$participant_id) %>%
  ggplot(aes(x = insight, y = appeal, group = participant_id, color = participant_id)) +
    geom_jitter(width = 0.05, height = 0.05, alpha = 0.6) +
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = "Relationship between Insight and Appeal for slopes < .3",
         x = "Insight",
         y = "Appeal") +
    theme_minimal() +
    guides(color = FALSE)

```

```{r}
# create quartiles based on the slope

slopes$quartile = cut(slopes$slope, breaks = quantile(slopes$slope, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), include.lowest = TRUE, )

# box plot of appeal depending on the quartile

data_Klopfenstein %>%
  left_join(slopes, by = "participant_id") %>%
  drop_na() %>%
  ggplot(aes(x = quartile, y = appeal, group = quartile, color = quartile)) +
    geom_boxplot() +
    labs(title = "Appeal by quartile of slope",
         x = "Quartile",
         y = "Appeal") +
    theme_minimal()

```

# Study 2

```{r, data preparation}
data_2 = read_csv("Data/Study2_data.csv")

# filter out participants who did not understand insight
data_2 = data_2 %>%
  filter(Q6 == 2)
```

```{r}
data_2 %>%
  summarize(mean_time = mean(as.numeric(`Duration (in seconds)`), na.rm = TRUE), sd_time = sd(as.numeric(`Duration (in seconds)`), na.rm = TRUE))
```
```{r}
data_2_cfa = data_2 %>%
  select(starts_with("Novel"), starts_with("Movie"), starts_with("Nonfict"), starts_with("Game"), starts_with("Docu")) %>%
  lapply(as.numeric) %>%
  as.data.frame()

data_2_cfa$ResponseId = data_2$ResponseId
```


```{r, Model_1}
model_1 <- "
  # Higher-order factor
  Curiosty =~ Insight_seeking + Explo_curiosity + Morbid_curiosity
  
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  Morbid_curiosity =~ Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

fit_1 = cfa(model_1, data = data_2_cfa, missing = "fiml", optim.method = "BFGS")

summary(fit_1, fit.measures = TRUE)
```


```{r, Model_2}
model_2 <- "
  # Single factor
  Curiosity =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight + Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo + Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
  
  # Control for media specific effect
  Novels =~ Novel_insight + Novel_explo + Novel_morbid
  Movies =~ Movie_insight + Movie_explo + Movie_morbid
  Nonfict =~ Nonfict_insight + Nonfict_explo + Nonfict_morbid
  Games =~ Game_insight + Game_explo + Game_morbid
  Docu =~ Docu_insight + Docu_explo + Docu_morbid
"

fit_2 = cfa(model_2, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")

summary(fit_2, standardized = TRUE, fit.measures = TRUE)
```



```{r}
model_3 <- "
  # Higher-order factor
  Curiosty =~ Insight_seeking + Explo_curiosity + Morbid_curiosity
  
  # First-order factors
  Insight_seeking =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight
  Explo_curiosity =~ Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo
  Morbid_curiosity =~ Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
"

model_4 <- "
  # Single factor
  Curiosity =~ Novel_insight + Movie_insight + Nonfict_insight + Game_insight + Docu_insight + Novel_explo + Movie_explo + Nonfict_explo + Game_explo + Docu_explo + Novel_morbid + Movie_morbid + Nonfict_morbid + Game_morbid + Docu_morbid
"

fit_3 = cfa(model_3, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")
fit_4 = cfa(model_4, data = data_2_cfa, missing = "FIML", optim.method = "BFGS")

semTools::net(fit_1,fit_2,fit_3, fit_4)
```

```{r}
lavaan::lavTestLRT(fit_1, fit_2, fit_3, fit_4)
```

```{r}
cfa_scores = lavPredict(fit_1)
```

```{r}
data_2 = cbind(data_2, cfa_scores)
```

```{r}
# Q71: 
# 1 = Natural and Physical Sciences
# 2 = Business
# 3 = Social Sciences
# 4 = Engineering and Computer Science
# 5 = Humanities
# 6 = Other majors
# 7 = Undeclared

# recode values: 

data_2$Q71 = recode(data_2$Q71, `1` = "Natural and Physical Sciences", `2` = "Business", `3` = "Social Sciences", `4` = "Engineering and Computer Science", `5` = "Humanities", `6` = "Other majors", `7` = "Undeclared")

# Q5: 

# 12 = Retired
# 9 = Unemployed
# 1 Agriculture, food, and natural resources
# 11 architecture and construction
# 2 Arts, audio/video technology, and communications
# 3 Business management and administration
# 4 Education and training
# 5 Finance
# 6 Government and public administration
# 7 Health science
# 10 Hospitality and tourism
# 8 Human services
# 13 Information technology
# 14 Law, public safety, corrections, and security
# 15 Manufacturing
# 16 Science, technology, engineering, and mathematics
# 17 Transportation, distribution, and logistics
# 18 Other

data_2$Q5 = recode(data_2$Q5, `1` = "Agriculture, food, and natural resources", `11` = "Architecture and construction", `2` = "Arts, audio/video technology, and communications", `3` = "Business management and administration", `4` = "Education and training", `5` = "Finance", `6` = "Government and public administration", `7` = "Health science", `10` = "Hospitality and tourism", `8` = "Human services", `13` = "Information technology", `14` = "Law, public safety, corrections, and security", `15` = "Manufacturing", `16` = "Science, technology, engineering, and mathematics", `17` = "Transportation, distribution, and logistics", `18` = "Other", `12` = "Retired", `9` = "Unemployed")


S2_RQ1_1 = lm(Insight_seeking ~ factor(Q5), data = data_2)
S2_RQ1_2 = lm(Explo_curiosity ~ factor(Q5), data = data_2)
S2_RQ1_3 = lm(Morbid_curiosity ~ factor(Q5), data = data_2)
S2_RQ1_4 = lm(Curiosty ~ factor(Q5), data = data_2)

summary(S2_RQ1_1)
```

```{r}
summary(S2_RQ1_2)
```

```{r}
summary(S2_RQ1_3)
```
```{r}
summary(S2_RQ1_4)
```
```{r}
library(jtools)

export_summs(S2_RQ1_1, S2_RQ1_2, S2_RQ1_3, S2_RQ1_4, model.names = c("Insight_seeking", "Explo_curiosity", "Morbid_curiosity", "Curiosty"), error_pos = "right", to.file = "html",
             file.name = "S2_RQ1.html")
```


```{r}
S2_RQ2_1 = lm(Insight_seeking ~ factor(Q71), data = data_2)
S2_RQ2_2 = lm(Explo_curiosity ~ factor(Q71), data = data_2)
S2_RQ2_3 = lm(Morbid_curiosity ~ factor(Q71), data = data_2)
S2_RQ2_4 = lm(Curiosty ~ factor(Q71), data = data_2)

summary(S2_RQ2_1)
```

```{r}
summary(S2_RQ2_2)
```

```{r}
summary(S2_RQ2_3)
```

```{r}
summary(S2_RQ2_4)
```

```{r}
# Descriptive Statistics:

data_2_cfa %>% 
  psych::describe()

```


```{r}
export_summs(S2_RQ2_1, S2_RQ2_2, S2_RQ2_3, S2_RQ2_4, model.names = c("Insight_seeking", "Explo_curiosity", "Morbid_curiosity", "Curiosty"), error_pos = "right", to.file = "html",
             file.name = "S2_RQ2.html")

```

```{r}
table(factor(data_2$Q71))
```

```{r}
kable(table(factor(data_2$Q5)), to.file = "html")
```


```{r}
# apply as.numeric

data_2$Novel_regularity = as.numeric(data_2$Novel_regularity)
data_2$Movie_regularity = as.numeric(data_2$Movie_regularity)
data_2$Nonfict_regularity = as.numeric(data_2$Nonfict_regularity)
data_2$Game_regularity = as.numeric(data_2$Game_regularity)
data_2$Docu_regularity = as.numeric(data_2$Docu_regularity)


data_2$mean_comsumption = rowMeans(data_2[,c("Novel_regularity", "Movie_regularity", "Nonfict_regularity", "Docu_regularity")])

summary(lm(mean_comsumption ~ factor(Q5), data = data_2))
```

```{r}
```

```{r}
```

